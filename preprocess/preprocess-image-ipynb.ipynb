{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-30T01:47:08.233867Z",
     "iopub.status.busy": "2024-12-30T01:47:08.233482Z",
     "iopub.status.idle": "2024-12-30T01:47:08.238153Z",
     "shell.execute_reply": "2024-12-30T01:47:08.237118Z",
     "shell.execute_reply.started": "2024-12-30T01:47:08.233836Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os                                     # interact with the operating system\n",
    "import shutil                                 # operating on file like copying, create and del directories and file\n",
    "from PIL import Image                         # image processing \n",
    "from multiprocessing.pool import ThreadPool   # parallelizing the process\n",
    "from tqdm import tqdm                         # for progess bar\n",
    "import glob                                   # for searcing the file with specific file pattern or name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-30T01:47:15.849452Z",
     "iopub.status.busy": "2024-12-30T01:47:15.848990Z",
     "iopub.status.idle": "2024-12-30T01:49:39.981250Z",
     "shell.execute_reply": "2024-12-30T01:49:39.980158Z",
     "shell.execute_reply.started": "2024-12-30T01:47:15.849419Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'processed_root = \"data\"\\n\\nos.makedirs(processed_root, exist_ok=True)\\nfor class_dir in os.listdir(original_root):\\n    class_path = os.path.join(original_root, class_dir)\\n    if os.path.isdir(class_path):\\n        frames_path = os.path.join(class_path, \"frames_sampled30\")\\n        if os.path.exists(frames_path):\\n            processed_class_path = os.path.join(processed_root, class_dir)\\n            os.makedirs(processed_class_path, exist_ok=True)\\n            # move all the images to the processed_class_path\\n            for img_file in os.listdir(frames_path):\\n                src = os.path.join(frames_path, img_file)\\n                dest = os.path.join(processed_class_path, img_file)\\n                shutil.copy(src, dest)\\n\\nprint(f\"Data preprocessing Completed\")  '"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"processed_root = \"data\"\n",
    "\n",
    "os.makedirs(processed_root, exist_ok=True)\n",
    "for class_dir in os.listdir(original_root):\n",
    "    class_path = os.path.join(original_root, class_dir)\n",
    "    if os.path.isdir(class_path):\n",
    "        frames_path = os.path.join(class_path, \"frames_sampled30\")\n",
    "        if os.path.exists(frames_path):\n",
    "            processed_class_path = os.path.join(processed_root, class_dir)\n",
    "            os.makedirs(processed_class_path, exist_ok=True)\n",
    "            # move all the images to the processed_class_path\n",
    "            for img_file in os.listdir(frames_path):\n",
    "                src = os.path.join(frames_path, img_file)\n",
    "                dest = os.path.join(processed_class_path, img_file)\n",
    "                shutil.copy(src, dest)\n",
    "\n",
    "print(f\"Data preprocessing Completed\")  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# calculating the total number of directory and images in each directory\n",
    "processed_root=\"/home/ritushwar/Nutritional-Assistance/data\"\n",
    "total_img = 0\n",
    "imgs_per_dir = []  # for making the list of images in each directory\n",
    "total_dirs = 0     # for calculating total no of directories\n",
    "for dir in os.listdir(processed_root): \n",
    "    processed_class_path = os.path.join(processed_root, dir)\n",
    "    if os.path.isdir(processed_class_path):\n",
    "        total_dirs +=1\n",
    "        img = 0            # for calculating total no of images in each directory\n",
    "        for im in os.listdir(processed_class_path):\n",
    "            img_path = os.path.join(processed_class_path, im)\n",
    "            if os.path.isfile(img_path):\n",
    "                img += 1\n",
    "                total_img +=1\n",
    "        imgs_per_dir.append(img)\n",
    "        if img == 29:\n",
    "            print(processed_class_path)\n",
    "        img = 0\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n"
     ]
    }
   ],
   "source": [
    "indx = imgs_per_dir.index(28, 0, -1)\n",
    "print(indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the unique number of images\n",
    "unq_img = set(imgs_per_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of directory: 4571\n",
      "Total no of images: 49647\n",
      "Unique set of images per directory: {2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total no of directory: {total_dirs}\")\n",
    "print(f\"Total no of images: {total_img}\")\n",
    "print(f\"Unique set of images per directory: {unq_img}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 1080)\n"
     ]
    }
   ],
   "source": [
    "# using pillow library\n",
    "img_path = \"/home/ritushwar/Nutritional-Assistance/camera_A_frame_003.jpeg\"\n",
    "image = Image.open(img_path)\n",
    "print(image.size)\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using resize method\n",
    "new_image = image.resize((200,200))\n",
    "new_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using thumbnail method\n",
    "image.thumbnail((320,320))\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All image are resized\n"
     ]
    }
   ],
   "source": [
    "for dir in os.listdir(processed_root):\n",
    "    processed_class_path = os.path.join(processed_root, dir)\n",
    "    if os.path.isdir(processed_class_path):\n",
    "        for img in os.listdir(processed_class_path):\n",
    "            image_path = os.path.join(processed_class_path, img)\n",
    "            if os.path.isfile(image_path):\n",
    "                org_image = Image.open(image_path)\n",
    "                image.thumbnail((320, 180))\n",
    "                image.save(image_path)\n",
    "\n",
    "print(\"All image are resized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting into tensor for iteration\n",
    "data_path = processed_root\n",
    "data_tensor = datasets.ImageFolder(\n",
    "    root=data_path,\n",
    "    transform=transforms.ToTensor(),\n",
    "    target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 180, 320])\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "image, label = data_tensor[0]\n",
    "print(image.shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = data_tensor.classes"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3848118,
     "sourceId": 6668957,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
